{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import math\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import transform\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# mode 0: read gray image with 3 channels and use those as inputs\n",
    "# mode 1: read gray image with 1 channel and use this only as input\n",
    "# mode 2: read gray image as one channel and add opt flow dx and dy to second and third channel\n",
    "mode = 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "outputs": [],
   "source": [
    "def get_opt_flow(p):\n",
    "    o_df = pd.read_csv(p)\n",
    "    o_df = o_df.drop(columns=[' 1st best', ' 2nd best'])\n",
    "    o_df = o_df.rename(columns={'# x': 'x', ' y': 'y', ' dx': 'dx', ' dy': 'dy'})\n",
    "    o_df = o_df.to_numpy()\n",
    "    #norm = np.linalg.norm(o_df)\n",
    "    #o_df = o_df / norm\n",
    "    return o_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "outputs": [],
   "source": [
    "class GazeEstimationDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, trans=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.trans = trans\n",
    "        self.frame = pd.read_csv(csv_file)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        img_name = self.frame.iloc[idx, 0]\n",
    "        img = cv2.imread(img_name)\n",
    "        img_gray = cv2.imread(img_name, 0)\n",
    "        x, y = img.shape[0], img.shape[1]\n",
    "        if mode == 1:\n",
    "            img_norm = cv2.normalize(img_gray, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "            img_norm = img_norm.reshape((x, y, 1))\n",
    "        elif mode == 0:\n",
    "            img_norm = cv2.normalize(img, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "        elif mode == 2:\n",
    "            img_norm = cv2.normalize(img, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "            img_norm[:, :, 1:3] = 0\n",
    "            opt_path = self.frame.iloc[idx, 5]\n",
    "            opt_path = \"/Users/PBL/PycharmProjects/sem_10/semester_thesis/\" + opt_path\n",
    "            opt_flow_df_norm = get_opt_flow(opt_path)\n",
    "            for row in opt_flow_df_norm:\n",
    "                ox, oy, odx, ody = row[0], row[1], row[2], row[3]\n",
    "                if not(dx==0) or not(dy==0):\n",
    "                    img_norm[oy, ox, 1] = dx\n",
    "                    img_norm[oy, ox, 2] = dy\n",
    "        else:\n",
    "            print('wrong mode')\n",
    "            return\n",
    "        face_img_coor = np.fromstring(self.frame.iloc[idx, 3][1:int(len(self.frame.iloc[idx, 3]) - 1)],\n",
    "                                      sep=',', dtype=int)\n",
    "        fx, fy, fw, fh = face_img_coor[0], face_img_coor[1], face_img_coor[2], face_img_coor[3]\n",
    "        face_img = img_norm[fy:fy+fh, fx:fx+fw, :]\n",
    "\n",
    "        x_gt = (self.frame.iloc[idx, 1] + 800) / 1600\n",
    "        y_gt = (self.frame.iloc[idx, 2] + 800) / 1600\n",
    "\n",
    "        sample = {'face': face_img, 'x': x_gt, 'y': y_gt}\n",
    "        if self.trans:\n",
    "            sample = self.trans(sample)\n",
    "        return sample\n",
    "\n",
    "\n",
    "class Rescale(object):\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        img = sample['face']\n",
    "\n",
    "        # h, w = image.shape[:2]\n",
    "        # if isinstance(self.output_size, int):\n",
    "        #    if h > w:\n",
    "        #        new_h, new_w = self.output_size * h / w, self.output_size\n",
    "        #    else:\n",
    "        #        new_h, new_w = self.output_size, self.output_size * w / h\n",
    "        # else:\n",
    "        new_h, new_w = self.output_size, self.output_size\n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "\n",
    "        img = transform.resize(img, (new_h, new_w))\n",
    "\n",
    "        x, y = sample['x'], sample['y']\n",
    "\n",
    "        return {'face': img, 'x': x, 'y': y}\n",
    "\n",
    "class ToTensor(object):\n",
    "    def __call__(self, sample):\n",
    "        img = sample['face']\n",
    "        x, y = sample['x'], sample['y']\n",
    "        img = img.transpose((2, 0, 1))\n",
    "        return {'face': torch.from_numpy(img).type(torch.DoubleTensor),\n",
    "                'gt_coor': torch.tensor([x, y]).type(torch.DoubleTensor)}\n",
    "\n",
    "\n",
    "class NetFaceGray(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(59536, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)  # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class NetFace3Chanel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(59536, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)  # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "outputs": [],
   "source": [
    "class GazeEstimationDatasetEyes(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, trans=None):\n",
    "        self.frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.trans = trans\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(len(self.frame))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        img_name = self.frame.iloc[idx, 0]\n",
    "        img = cv2.imread(img_name)\n",
    "        img_gray = cv2.imread(img_name, 0)\n",
    "        x, y = int(img_gray.shape[0]), int(img_gray.shape[1])\n",
    "        if mode == 1:\n",
    "            img_norm_eyes = cv2.normalize(img_gray, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "            img_norm_eyes = img_norm_eyes.reshape((x, y, 1))\n",
    "        elif mode == 0:\n",
    "            img_norm_eyes = cv2.normalize(img, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "        elif mode == 2:\n",
    "            img_norm_eyes = cv2.normalize(img, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "            img_norm_eyes[:, :, 1:3] = 0\n",
    "            opt_path = self.frame.iloc[idx, 5]\n",
    "            opt_path = \"/Users/PBL/PycharmProjects/sem_10/semester_thesis/\" + opt_path\n",
    "            opt_flow_df_norm = get_opt_flow(opt_path)\n",
    "            for row in opt_flow_df_norm:\n",
    "                ox, oy, odx, ody = row[0], row[1], row[2], row[3]\n",
    "                if not(dx==0) or not(dy==0):\n",
    "                    img_norm_eyes[oy, ox, 1] = dx\n",
    "                    img_norm_eyes[oy, ox, 2] = dy\n",
    "        else:\n",
    "            print('wrong mode')\n",
    "            return\n",
    "\n",
    "\n",
    "        eyes_roi = np.fromstring(self.frame.iloc[idx, 4][1:int(len(self.frame.iloc[idx, 4]) - 1)],\n",
    "                                      sep=',', dtype=int)\n",
    "        x_eye, y_eye, w, h = eyes_roi[0], eyes_roi[1], eyes_roi[2], eyes_roi[3]\n",
    "\n",
    "        eyes_img = img_norm_eyes[y_eye: y_eye + h, x_eye: x_eye + w, :]\n",
    "\n",
    "        x_gt = (self.frame.iloc[idx, 1] + 800) / 1600\n",
    "        y_gt = (self.frame.iloc[idx, 2] + 800) / 1600\n",
    "\n",
    "        sample = {'eyes_img': eyes_img, 'x': x_gt, 'y': y_gt}\n",
    "\n",
    "        if self.trans:\n",
    "            sample = self.trans(sample)\n",
    "\n",
    "        return sample\n",
    "\n",
    "class RescaleEyes(object):\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        img = sample['eyes_img']\n",
    "\n",
    "        # h, w = image.shape[:2]\n",
    "        # if isinstance(self.output_size, int):\n",
    "        #    if h > w:\n",
    "        #        new_h, new_w = self.output_size * h / w, self.output_size\n",
    "        #    else:\n",
    "        #        new_h, new_w = self.output_size, self.output_size * w / h\n",
    "        # else:\n",
    "        new_h, new_w = self.output_size, self.output_size\n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "\n",
    "        img = transform.resize(img, (new_h, new_w))\n",
    "\n",
    "        x, y = sample['x'], sample['y']\n",
    "\n",
    "        return {'eyes_img': img, 'x': x, 'y': y}\n",
    "\n",
    "class ToTensorEyes(object):\n",
    "    def __call__(self, sample):\n",
    "        img = sample['eyes_img']\n",
    "        x, y = sample['x'], sample['y']\n",
    "        img = img.transpose((2, 0, 1))\n",
    "        return {'eyes_img': torch.from_numpy(img).type(torch.DoubleTensor),\n",
    "                'gt_coor': torch.tensor([x, y]).type(torch.DoubleTensor)}\n",
    "\n",
    "class NetEyesGray(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(13456, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)  # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class NetEyesRGB(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(13456, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)  # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "outputs": [],
   "source": [
    "transformed_dataset = GazeEstimationDataset(csv_file=\"full_face/total.csv\", root_dir=\"\",\n",
    "                                            trans=transforms.Compose([Rescale(256), ToTensor()]))\n",
    "transformed_dataset_eyes = GazeEstimationDatasetEyes(csv_file=\"full_face/total.csv\", root_dir=\"\",\n",
    "                                            trans=transforms.Compose([RescaleEyes(128), ToTensorEyes()]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "datasets containing full face pictures"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(transformed_dataset))\n",
    "test_size = len(transformed_dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(transformed_dataset, [train_size, test_size])\n",
    "\n",
    "train_size = int(0.95 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "outputs": [],
   "source": [
    "batch_size = 15\n",
    "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "valloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "testloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "model_gray = NetFaceGray().to(device)\n",
    "model_gray = model_gray.double()\n",
    "criterion_gray = nn.MSELoss().to(device)\n",
    "optimizer_gray = optim.Adam(model_gray.parameters(), lr=0.001)\n",
    "\n",
    "model_rgb = NetFace3Chanel().to(device)\n",
    "model_rgb = model_rgb.double()\n",
    "criterion_rgb = nn.MSELoss().to(device)\n",
    "optimizer_rgb = optim.Adam(model_rgb.parameters(), lr=0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training 0:  15%|█▌        | 32/212 [01:35<08:34,  2.86s/batch, distance=35.9, train_loss=0.0707]"
     ]
    }
   ],
   "source": [
    "n = 30\n",
    "train_loss_arr = []\n",
    "val_loss_arr = []\n",
    "train_dist_arr = []\n",
    "val_dist_arr = []\n",
    "for epoch in range(n):\n",
    "    with tqdm(trainloader, unit=\"batch\") as tepoch:\n",
    "        for data in tepoch:\n",
    "            tepoch.set_description(f\"Training {epoch}\")\n",
    "            faces = data['face']\n",
    "            labels = data['gt_coor']\n",
    "\n",
    "            if mode == 1:\n",
    "                optimizer_gray.zero_grad()\n",
    "                output = model_gray(faces)\n",
    "                train_loss = criterion_gray(output, labels)\n",
    "                train_loss.backward()\n",
    "                optimizer_gray.step()\n",
    "            elif mode == 0 or mode == 2:\n",
    "                optimizer_rgb.zero_grad()\n",
    "                output = model_rgb(faces)\n",
    "                train_loss = criterion_rgb(output, labels)\n",
    "                train_loss.backward()\n",
    "                optimizer_rgb.step()\n",
    "            else:\n",
    "                print('wrong mode')\n",
    "                break\n",
    "\n",
    "            batch_dist = 0\n",
    "\n",
    "            for i in range (len(output)):\n",
    "                out_x, out_y = output[i][0], output[i][1]\n",
    "                lab_x, lab_y = labels[i][0], labels[i][1]\n",
    "                dx = out_x - lab_x\n",
    "                dy = out_y - lab_y\n",
    "                dist = math.sqrt(dx*dx + dy*dy)\n",
    "                batch_dist += dist\n",
    "\n",
    "            label_name = \"Epoch \" + str(epoch)\n",
    "\n",
    "            #correct = (abs(output - labels)).sum().item()\n",
    "            distance = batch_dist / len(output)\n",
    "            train_dist_arr.append(distance*100)\n",
    "            train_loss_arr.append(train_loss.item())\n",
    "            tepoch.set_postfix(train_loss=train_loss.item(), distance=100*distance)\n",
    "\n",
    "        #print(\"train loss value: \", running_loss/len(trainloader))\n",
    "\n",
    "    with tqdm(valloader, unit=\"batch\") as tepoch:\n",
    "        with torch.no_grad():\n",
    "            if mode == 1:\n",
    "                model_gray.eval()\n",
    "                for data in tepoch:\n",
    "                    tepoch.set_description(f\"Validation {epoch}\")\n",
    "                    faces = data['face']\n",
    "                    labels = data['gt_coor']\n",
    "                    #labels = [0.5, 0.5]\n",
    "                    output = model_gray(faces)\n",
    "                    loss = criterion_gray(output, labels)\n",
    "                    val_loss = loss.item()*faces.size(0)\n",
    "                    batch_dist = 0\n",
    "                    for i in range (len(output)):\n",
    "                        out_x, out_y = output[i][0], output[i][1]\n",
    "                        lab_x, lab_y = labels[i][0], labels[i][1]\n",
    "                        dx = out_x - lab_x\n",
    "                        dy = out_y - lab_y\n",
    "                        dist = math.sqrt(dx*dx + dy*dy)\n",
    "                        batch_dist += dist\n",
    "\n",
    "                    val_dist = batch_dist / len(output)\n",
    "                    val_dist_arr.append(val_dist*100)\n",
    "                    val_loss_arr.append(val_loss)\n",
    "                    tepoch.set_postfix(val_loss=val_loss, val_dist=100*val_dist)\n",
    "            elif mode == 0 or mode == 2:\n",
    "                model_rgb.eval()\n",
    "                for data in tepoch:\n",
    "                    tepoch.set_description(f\"Validation {epoch}\")\n",
    "                    faces = data['face']\n",
    "                    labels = data['gt_coor']\n",
    "                    #labels = [0.5, 0.5]\n",
    "                    output = model_rgb(faces)\n",
    "                    loss = criterion_rgb(output, labels)\n",
    "                    val_loss = loss.item()*faces.size(0)\n",
    "                    batch_dist = 0\n",
    "                    for i in range (len(output)):\n",
    "                        out_x, out_y = output[i][0], output[i][1]\n",
    "                        lab_x, lab_y = labels[i][0], labels[i][1]\n",
    "                        dx = out_x - lab_x\n",
    "                        dy = out_y - lab_y\n",
    "                        dist = math.sqrt(dx*dx + dy*dy)\n",
    "                        batch_dist += dist\n",
    "\n",
    "                    val_dist = batch_dist / len(output)\n",
    "                    val_dist_arr.append(val_dist*100)\n",
    "                    val_loss_arr.append(val_loss)\n",
    "                    tepoch.set_postfix(val_loss=val_loss, val_dist=100*val_dist)\n",
    "\n",
    "print('done')\n",
    "if mode == 1:\n",
    "    path = './trained_face_gray.pth'\n",
    "    torch.save(model_gray.state_dict(), path)\n",
    "elif mode == 0:\n",
    "    path = './trained_face_3chanel.pth'\n",
    "    torch.save(model_rgb.state_dict(), path)\n",
    "elif mode == 2:\n",
    "    path = './trained_face_opt.pth'\n",
    "    torch.save(model_rgb.state_dict(), path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "visualizing the distance and loss from previous training with face"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train_dist = [x for x in range(len(train_dist_arr))]\n",
    "x_train_loss = [x for x in range(len(train_loss_arr))]\n",
    "\n",
    "x_val_dist = [x for x in range(len(val_dist_arr))]\n",
    "x_val_loss = [x for x in range(len(val_loss_arr))]\n",
    "\n",
    "fig, axs = plt.subplots(2,2, figsize=(16,9))\n",
    "\n",
    "axs[0,0].plot(x_train_dist, train_dist_arr)\n",
    "axs[0,0].set_title('Training distances')\n",
    "axs[0,1].plot(x_train_loss, train_loss_arr)\n",
    "axs[0,1].set_title('Training losses')\n",
    "axs[1,0].plot(x_val_dist, val_dist_arr)\n",
    "axs[1,0].set_title('Validation distances')\n",
    "axs[1,1].plot(x_val_loss, val_loss_arr)\n",
    "axs[1,1].set_title('Validation losses')\n",
    "\n",
    "if mode == 1:\n",
    "    plt.savefig(\"face_gray.jpg\")\n",
    "elif mode == 0:\n",
    "    plt.savefig(\"face_3channel.jpg\")\n",
    "elif mode == 2:\n",
    "    plt.savefig(\"face_opt.jpg\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if mode == 1:\n",
    "    path = './trained_face_gray.pth'\n",
    "    model_gray.load_state_dict(torch.load(path))\n",
    "    distances_face = []\n",
    "    gt_face = []\n",
    "    guess_face = []\n",
    "    with torch.no_grad():\n",
    "        with tqdm(testloader, unit=\"batch\") as tepoch:\n",
    "            for data in tepoch:\n",
    "                image = data['face']\n",
    "                #labels = [0.5, 0.5]\n",
    "                labels = data['gt_coor']\n",
    "                gt_face.append(labels)\n",
    "                output = model_gray(image)\n",
    "                guess_face.append(output)\n",
    "                dim = len(output)\n",
    "                batch_dist = 0\n",
    "                for i in range(dim):\n",
    "                    out_x, out_y = output[i][0], output[i][1]\n",
    "                    lab_x, lab_y = labels[i][0], labels[i][1]\n",
    "                    dx = out_x - lab_x\n",
    "                    dy = out_y - lab_y\n",
    "                    dist = math.sqrt(dx*dx + dy*dy)\n",
    "                    batch_dist += dist\n",
    "\n",
    "                distance = batch_dist / len(output)\n",
    "                distances_face.append(distance)\n",
    "                tepoch.set_postfix(distance=100*distance)\n",
    "    print(\"done\")\n",
    "#still TODO gt, distances etc\n",
    "elif mode == 0:\n",
    "    path = './trained_face_3chanel.pth'\n",
    "    model_rgb.load_state_dict(torch.load(path))\n",
    "    distances_face_3channel = []\n",
    "    with torch.no_grad():\n",
    "        with tqdm(testloader, unit=\"batch\") as tepoch:\n",
    "            for data in tepoch:\n",
    "                image = data['face']\n",
    "                #labels = [0.5, 0.5]\n",
    "                labels = data['gt_coor']\n",
    "                output = model_rgb(image)\n",
    "                dim = len(output)\n",
    "                batch_dist = 0\n",
    "                for i in range(dim):\n",
    "                    out_x, out_y = output[i][0], output[i][1]\n",
    "                    lab_x, lab_y = labels[i][0], labels[i][1]\n",
    "                    dx = out_x - lab_x\n",
    "                    dy = out_y - lab_y\n",
    "                    dist = math.sqrt(dx*dx + dy*dy)\n",
    "                    batch_dist += dist\n",
    "\n",
    "                distance = batch_dist / len(output)\n",
    "                distances_face_3channel.append(distance)\n",
    "                tepoch.set_postfix(distance=100*distance)\n",
    "    print(\"done\")\n",
    "elif mode == 2:\n",
    "    path = './trained_face_opt.pth'\n",
    "    model_rgb.load_state_dict(torch.load(path))\n",
    "    distances_face_opt = []\n",
    "    with torch.no_grad():\n",
    "        with tqdm(testloader, unit=\"batch\") as tepoch:\n",
    "            for data in tepoch:\n",
    "                image = data['face']\n",
    "                #labels = [0.5, 0.5]\n",
    "                labels = data['gt_coor']\n",
    "                output = model_rgb(image)\n",
    "                dim = len(output)\n",
    "                batch_dist = 0\n",
    "                for i in range(dim):\n",
    "                    out_x, out_y = output[i][0], output[i][1]\n",
    "                    lab_x, lab_y = labels[i][0], labels[i][1]\n",
    "                    dx = out_x - lab_x\n",
    "                    dy = out_y - lab_y\n",
    "                    dist = math.sqrt(dx*dx + dy*dy)\n",
    "                    batch_dist += dist\n",
    "\n",
    "                distance = batch_dist / len(output)\n",
    "                distances_face_opt.append(distance)\n",
    "                tepoch.set_postfix(distance=100*distance)\n",
    "    print(\"done\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "visualizing the testing performance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "dataset containing only eye portion 40FPS"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(transformed_dataset_eyes))\n",
    "test_size = len(transformed_dataset_eyes) - train_size\n",
    "train_dataset_eyes, test_dataset_eyes = torch.utils.data.random_split(transformed_dataset_eyes, [train_size, test_size])\n",
    "\n",
    "train_size = int(0.95 * len(train_dataset_eyes))\n",
    "val_size = len(train_dataset_eyes) - train_size\n",
    "train_dataset_eyes, val_dataset_eyes = torch.utils.data.random_split(train_dataset_eyes, [train_size, val_size])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "batch_size = 15\n",
    "trainloader_eyes = DataLoader(train_dataset_eyes, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "valloader_eyes = DataLoader(val_dataset_eyes, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "testloader_eyes = DataLoader(test_dataset_eyes, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "\n",
    "model_eyes_gray = NetEyesGray().to(device)\n",
    "model_eyes_gray = model_eyes_gray.double()\n",
    "criterion_eyes_gray = nn.MSELoss().to(device)\n",
    "optimizer_eyes_gray = optim.Adam(model_eyes_gray.parameters(), lr=0.001)\n",
    "\n",
    "model_eyes_3chanel = NetEyesRGB().to(device)\n",
    "model_eyes_3chanel = model_eyes_3chanel.double()\n",
    "criterion_eyes_3chanel = nn.MSELoss().to(device)\n",
    "optimizer_eyes_3chanel = optim.Adam(model_eyes_3chanel.parameters(), lr=0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n = 30\n",
    "min_valid_loos = np.inf\n",
    "train_eyes_loss_arr = []\n",
    "val_eyes_loss_arr = []\n",
    "train_eyes_dist_arr = []\n",
    "val_eyes_dist_arr = []\n",
    "for epoch in range(n):\n",
    "    with tqdm(trainloader_eyes, unit=\"batch\") as tepoch:\n",
    "        for data in tepoch:\n",
    "            tepoch.set_description(f\"Training {epoch}\")\n",
    "            inputs = data['eyes_img']\n",
    "            labels = data['gt_coor']\n",
    "            optical_flow = data['opt_flow']\n",
    "            if mode == 1:\n",
    "                optimizer_eyes_gray.zero_grad()\n",
    "                output = model_eyes_gray(inputs)\n",
    "                train_loss = criterion_eyes_gray(output, labels)\n",
    "                train_loss.backward()\n",
    "                optimizer_eyes_gray.step()\n",
    "            elif mode == 0 or mode == 2:\n",
    "                optimizer_eyes_3chanel.zero_grad()\n",
    "                output = model_eyes_3chanel(inputs)\n",
    "                train_loss = criterion_eyes_3chanel(output, labels)\n",
    "                train_loss.backward()\n",
    "                optimizer_eyes_3chanel.step()\n",
    "\n",
    "            batch_dist = 0\n",
    "            for i in range (len(output)):\n",
    "                out_x, out_y = output[i][0], output[i][1]\n",
    "                lab_x, lab_y = labels[i][0], labels[i][1]\n",
    "                dx = out_x - lab_x\n",
    "                dy = out_y - lab_y\n",
    "                dist = math.sqrt(dx*dx + dy*dy)\n",
    "                batch_dist += dist\n",
    "\n",
    "            distance = batch_dist / len(output)\n",
    "            train_eyes_dist_arr.append(distance*100)\n",
    "            train_eyes_loss_arr.append(train_loss.item())\n",
    "            tepoch.set_postfix(train_loss=train_loss.item(), distance=100*distance)\n",
    "\n",
    "\n",
    "    with tqdm(valloader_eyes, unit=\"batch\") as tepoch:\n",
    "        with torch.no_grad():\n",
    "            if mode == 1:\n",
    "                model_eyes_gray.eval()\n",
    "                for data in tepoch:\n",
    "                    tepoch.set_description(f\"Validation {epoch}\")\n",
    "                    inputs = data['eyes_img']\n",
    "                    labels = data['gt_coor']\n",
    "                    #labels = [0.5, 0.5]\n",
    "                    output = model_eyes_gray(inputs)\n",
    "                    loss = criterion_eyes_gray(output, labels)\n",
    "                    val_loss = loss.item()*inputs.size(0)\n",
    "                    batch_dist = 0\n",
    "                    for i in range (len(output)):\n",
    "                        out_x, out_y = output[i][0], output[i][1]\n",
    "                        lab_x, lab_y = labels[i][0], labels[i][1]\n",
    "                        dx = out_x - lab_x\n",
    "                        dy = out_y - lab_y\n",
    "                        dist = math.sqrt(dx*dx + dy*dy)\n",
    "                        batch_dist += dist\n",
    "\n",
    "                    val_dist = batch_dist / len(output)\n",
    "                    val_eyes_dist_arr.append(val_dist*100)\n",
    "                    val_eyes_loss_arr.append(val_loss)\n",
    "                    tepoch.set_postfix(val_loss=val_loss, val_acc=100*val_dist)\n",
    "            if mode == 0 or mode == 2:\n",
    "                model_eyes_3chanel.eval()\n",
    "                for data in tepoch:\n",
    "                    tepoch.set_description(f\"Validation {epoch}\")\n",
    "                    inputs = data['eyes_img']\n",
    "                    labels = data['gt_coor']\n",
    "                    #labels = [0.5, 0.5]\n",
    "                    output = model_eyes_3chanel(inputs)\n",
    "                    loss = criterion_eyes_3chanel(output, labels)\n",
    "                    val_loss = loss.item()*inputs.size(0)\n",
    "                    batch_dist = 0\n",
    "                    for i in range (len(output)):\n",
    "                        out_x, out_y = output[i][0], output[i][1]\n",
    "                        lab_x, lab_y = labels[i][0], labels[i][1]\n",
    "                        dx = out_x - lab_x\n",
    "                        dy = out_y - lab_y\n",
    "                        dist = math.sqrt(dx*dx + dy*dy)\n",
    "                        batch_dist += dist\n",
    "\n",
    "                    val_dist = batch_dist / len(output)\n",
    "                    val_eyes_dist_arr.append(val_dist*100)\n",
    "                    val_eyes_loss_arr.append(val_loss)\n",
    "                    tepoch.set_postfix(val_loss=val_loss, val_acc=100*val_dist)\n",
    "\n",
    "\n",
    "print('done')\n",
    "if mode == 1:\n",
    "    path = './trained_eyes_gray.pth'\n",
    "    torch.save(model_eyes_gray.state_dict(), path)\n",
    "elif mode == 0:\n",
    "    path = './trained_eyes_3chanel.pth'\n",
    "    torch.save(model_eyes_3chanel.state_dict(), path)\n",
    "elif mode == 2:\n",
    "    path = './trained_eyes_opt.pth'\n",
    "    torch.save(model_eyes_3chanel.state_dict(), path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "visualizing performance for eye region only"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train_dist = [x for x in range(len(train_eyes_dist_arr))]\n",
    "x_train_loss = [x for x in range(len(train_eyes_loss_arr))]\n",
    "\n",
    "x_val_dist = [x for x in range(len(val_eyes_dist_arr))]\n",
    "x_val_loss = [x for x in range(len(val_eyes_loss_arr))]\n",
    "\n",
    "fig, axs = plt.subplots(2,2, figsize=(16,9))\n",
    "\n",
    "axs[0,0].plot(x_train_dist, train_eyes_dist_arr)\n",
    "axs[0,0].set_title('Training distances')\n",
    "axs[0,1].plot(x_train_loss, train_eyes_loss_arr)\n",
    "axs[0,1].set_title('Training losses')\n",
    "axs[1,0].plot(x_val_dist, val_eyes_dist_arr)\n",
    "axs[1,0].set_title('Validation distances')\n",
    "axs[1,1].plot(x_val_loss, val_eyes_loss_arr)\n",
    "axs[1,1].set_title('Validation losses')\n",
    "\n",
    "if mode == 1:\n",
    "    plt.savefig(\"eye_gray.jpg\")\n",
    "elif mode == 0:\n",
    "    plt.savefig(\"eye_3channel.jpg\")\n",
    "elif mode == 2:\n",
    "    plt.savefig(\"eye_opt.jpg\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if mode == 1:\n",
    "    distances_eyes = []\n",
    "    gt_eyes = []\n",
    "    guess_eyes = []\n",
    "    path = './trained_eyes_gray.pth'\n",
    "    model_eyes_gray.load_state_dict(torch.load(path))\n",
    "    with torch.no_grad():\n",
    "        with tqdm(testloader_eyes, unit=\"batch\") as tepoch:\n",
    "            for data in tepoch:\n",
    "                image = data['eyes_img']\n",
    "                labels = data['gt_coor']\n",
    "                gt_eyes.append(labels)\n",
    "                # labels = [0.5, 0.5]\n",
    "                output = model_eyes_gray(image)\n",
    "                guess_eyes.append(output)\n",
    "                dim = len(output)\n",
    "                batch_dist = 0\n",
    "                for i in range(dim):\n",
    "                    out_x, out_y = output[i][0], output[i][1]\n",
    "                    lab_x, lab_y = labels[i][0], labels[i][1]\n",
    "                    dx = out_x - lab_x\n",
    "                    dy = out_y - lab_y\n",
    "                    dist = math.sqrt(dx*dx + dy*dy)\n",
    "                    batch_dist += dist\n",
    "\n",
    "                distance = batch_dist / len(output)\n",
    "                distances_eyes.append(distance*100)\n",
    "                tepoch.set_postfix(distance=100*distance)\n",
    "    print(\"done\")\n",
    "\n",
    "# still TODO gt, distances etc\n",
    "elif mode == 0:\n",
    "    path = './trained_eyes_3chanel.pth'\n",
    "    model_eyes_3chanel.load_state_dict(torch.load(path))\n",
    "    distances_eyes_3channel = []\n",
    "    with torch.no_grad():\n",
    "        with tqdm(testloader_eyes, unit=\"batch\") as tepoch:\n",
    "            for data in tepoch:\n",
    "                image = data['eyes_img']\n",
    "                labels = data['gt_coor']\n",
    "                # labels = [0.5, 0.5]\n",
    "                output = model_eyes_3chanel(image)\n",
    "                dim = len(output)\n",
    "                batch_dist = 0\n",
    "                for i in range(dim):\n",
    "                    out_x, out_y = output[i][0], output[i][1]\n",
    "                    lab_x, lab_y = labels[i][0], labels[i][1]\n",
    "                    dx = out_x - lab_x\n",
    "                    dy = out_y - lab_y\n",
    "                    dist = math.sqrt(dx*dx + dy*dy)\n",
    "                    batch_dist += dist\n",
    "\n",
    "                distance = batch_dist / len(output)\n",
    "                distances_eyes_3channel.append(distance*100)\n",
    "                tepoch.set_postfix(distance=100*distance)\n",
    "    print(\"done\")\n",
    "elif mode == 2:\n",
    "    path = './trained_eyes_opt.pth'\n",
    "    model_eyes_3chanel.load_state_dict(torch.load(path))\n",
    "    #print(net)\n",
    "    distances_eyes_opt = []\n",
    "    with torch.no_grad():\n",
    "        with tqdm(testloader_eyes, unit=\"batch\") as tepoch:\n",
    "            for data in tepoch:\n",
    "                image = data['eyes_img']\n",
    "                labels = data['gt_coor']\n",
    "                # labels = [0.5, 0.5]\n",
    "                output = model_eyes_3chanel(image)\n",
    "                dim = len(output)\n",
    "                batch_dist = 0\n",
    "                for i in range(dim):\n",
    "                    out_x, out_y = output[i][0], output[i][1]\n",
    "                    lab_x, lab_y = labels[i][0], labels[i][1]\n",
    "                    dx = out_x - lab_x\n",
    "                    dy = out_y - lab_y\n",
    "                    dist = math.sqrt(dx*dx + dy*dy)\n",
    "                    batch_dist += dist\n",
    "\n",
    "                distance = batch_dist / len(output)\n",
    "                distances_eyes_opt.append(distance*100)\n",
    "                tepoch.set_postfix(distance=100*distance)\n",
    "    print(\"done\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}